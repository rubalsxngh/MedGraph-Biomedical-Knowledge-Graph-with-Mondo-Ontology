{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALL THE EXTERNAL REUIQREMENTS ARE PRESNET IN ./requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#error can occur, careful!!\n",
    "%pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.0.0/en_core_web_md-3.0.0.tar.gz\n",
    "%pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_ner_bc5cdr_md-0.4.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd_path= os.getcwd()\n",
    "cwd_path= cwd_path.replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets scrape the required dataset \n",
    "Input will be a text file containing articles abstracts from pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results saved to a text file.\n"
     ]
    }
   ],
   "source": [
    "from my_packages.get_document import module_get_document\n",
    "\n",
    "kg_disease= str(input(\"please enter the disease you want a knowledge graph for: \"))\n",
    "no_of_articles= int(input(\"please enter the number of articles you want to consider: \")) #expected wall time for 10 articles around 12 mins\n",
    "dataset_file_path= cwd_path + \"/datasets/dataset.txt\"\n",
    "\n",
    "module_get_document.get_docx(kg_disease, no_of_articles, dataset_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets crete a log file for ouputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_path= cwd_path + \"/ouput/output_log.txt\"\n",
    "\n",
    "try:\n",
    "    with open(log_file_path, 'w') as fh:\n",
    "        fh.write(\"welcome to the log file!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a dataframe that can be later deployed to neo4J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\VIISem\\knowledgeGraphUsingMondo\\.conda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "100%|██████████| 122/122 [03:55<00:00,  1.93s/it]\n"
     ]
    }
   ],
   "source": [
    "from my_packages.get_knowledgeGraph import module_getKnowledgeGrpah\n",
    "\n",
    "output_df_path= module_getKnowledgeGrpah.get_gph(cwd_path, log_file_path, dataset_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets deploy df to neo4J :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total': 118, 'batches': 1, 'time': 5.584398984909058}\n",
      "{'total': 0, 'batches': 1, 'time': 3.4603235721588135}\n",
      "{'total': 0, 'batches': 1, 'time': 1.9675333499908447}\n",
      "{'total': 0, 'batches': 1, 'time': 0.8836343288421631}\n"
     ]
    }
   ],
   "source": [
    "from my_packages.create_graph import module_createGraph\n",
    "#the load_gh fn takes input of bolt url and password of sandbox, create your own sandbow on neo4J\n",
    "class_labels= module_createGraph.load_gh(\"bolt://44.202.158.190:7687\", \"autos-volumes-correction\", output_df_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ignore below if you dont need to check efficiency!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**calculating the efficiency of 5 abastract indivially**\n",
    "- manually abstracting entites from each abstact\n",
    "- creating a list of list\n",
    "- chcking acciracy, no of enties found, no of entites not found\n",
    "- returning a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\VIISem\\knowledgeGraphUsingMondo\\.conda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from check_efficiency import module_get_efficiency, get_data\n",
    "df= []\n",
    "dataset, entities_list= get_data.dataset, get_data.entities_list\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    accuracy= module_get_efficiency.check_ef(dataset[i], entities_list[i])\n",
    "    df.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextIOWrapper.write() takes exactly one argument (0 given)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1= pd.DataFrame(df, columns= ['Precsion', 'Recall', 'F1_Score'], index=None)\n",
    "df1['Article_no'] = range(1, len(df) + 1)\n",
    "df1.set_index('Article_no', inplace=True)\n",
    "\n",
    "accuracy_score_output= cwd_path+ \"/ouput/accuracy_score.csv\"\n",
    "try:\n",
    "    with open(accuracy_score_output, 'w') as fh:\n",
    "        fh.write()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "df1.to_csv(accuracy_score_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
